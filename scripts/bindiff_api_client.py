#!/usr/bin/env python3
"""
BinDiff API å®¢æˆ·ç«¯è„šæœ¬
æ”¯æŒç›®å½•æ‰«æã€æ‰¹é‡ç›¸ä¼¼åº¦æœç´¢å’Œç»“æœJSONè¾“å‡º

åŠŸèƒ½ç‰¹æ€§:
- è‡ªåŠ¨æ‰«æç›®æ ‡ç›®å½•ä¸­çš„å¯æ‰§è¡Œæ–‡ä»¶
- é€šè¿‡APIè°ƒç”¨BinDiffç›¸ä¼¼åº¦æœç´¢æœåŠ¡
- æ”¯æŒæ‰¹é‡å¤„ç†å’Œå¹¶å‘è¯·æ±‚
- å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- ç»“æœä¿å­˜ä¸ºJSONæ ¼å¼
- æ”¯æŒå¤šç§è¾“å‡ºæ¨¡å¼å’Œè¿‡æ»¤æ¡ä»¶

ä½œè€…: BinDiff API Client
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import json
import time
import argparse
import requests
import hashlib
import magic
from pathlib import Path
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

class BinDiffAPIClient:
    """BinDiff APIå®¢æˆ·ç«¯ç±»"""
    
    def __init__(self, base_url: str = "http://localhost:5001", timeout: int = 300):
        """
        åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        
        Args:
            base_url: BinDiffæœåŠ¡çš„åŸºç¡€URL
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'BinDiff-API-Client/1.0.0'
        })
        
    def check_service_health(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            logger.info("æ­£åœ¨æ£€æŸ¥BinDiffæœåŠ¡çŠ¶æ€...")
            
            # æ£€æŸ¥ç›¸ä¼¼åº¦æœç´¢API
            response = self.session.get(
                f"{self.base_url}/similarity/api/database/info",
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                if data.get('success'):
                    logger.info(f"âœ… BinDiffæœåŠ¡æ­£å¸¸è¿è¡Œ")
                    logger.info(f"ğŸ“Š æ•°æ®åº“ç»Ÿè®¡: {data.get('statistics', {})}")
                    return True
            
            logger.error(f"âŒ æœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            return False
            
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ æ— æ³•è¿æ¥åˆ°BinDiffæœåŠ¡: {e}")
            return False
            
    def get_database_info(self) -> Optional[Dict]:
        """è·å–æ•°æ®åº“ä¿¡æ¯"""
        try:
            response = self.session.get(
                f"{self.base_url}/similarity/api/database/info",
                timeout=self.timeout
            )
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"è·å–æ•°æ®åº“ä¿¡æ¯å¤±è´¥: {e}")
            return None
            
    def request_cleanup(self) -> bool:
        """è¯·æ±‚æœåŠ¡ç«¯æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            logger.info("ğŸ§¹ è¯·æ±‚æœåŠ¡ç«¯æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
            
            response = self.session.post(
                f"{self.base_url}/similarity/api/cleanup",
                timeout=30  # æ¸…ç†æ“ä½œå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´
            )
            
            if response.status_code == 200:
                data = response.json()
                if data.get('success'):
                    cleaned_files = data.get('cleaned_files', 0)
                    message = data.get('message', 'æ¸…ç†å®Œæˆ')
                    logger.info(f"âœ… {message}")
                    if cleaned_files > 0:
                        logger.info(f"ğŸ—‘ï¸ æ¸…ç†äº† {cleaned_files} ä¸ªä¸´æ—¶æ–‡ä»¶")
                    return True
                else:
                    logger.error(f"âŒ æœåŠ¡ç«¯æ¸…ç†å¤±è´¥: {data.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    return False
            else:
                logger.warning(f"âš ï¸ æ¸…ç†è¯·æ±‚å¤±è´¥ (HTTP {response.status_code})")
                logger.info("ğŸ’¡ æç¤ºï¼šæœåŠ¡ç«¯å·²åœ¨æ¯æ¬¡æœç´¢åè‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
                return False
            
        except requests.exceptions.RequestException as e:
            logger.warning(f"âš ï¸ æ— æ³•è¿æ¥æ¸…ç†æ¥å£: {e}")
            logger.info("ğŸ’¡ æç¤ºï¼šæœåŠ¡ç«¯å·²åœ¨æ¯æ¬¡æœç´¢åè‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
            logger.info("ğŸ“ å¦‚éœ€æ‰‹åŠ¨æ¸…ç†ï¼Œå¯åœ¨æœåŠ¡å™¨ä¸Šæ‰§è¡Œ: rm -rf ./out/*")
            return False
        except Exception as e:
            logger.error(f"è¯·æ±‚æ¸…ç†å¤±è´¥: {e}")
            return False
            
    def search_similarity(self, file_path: str, top_k: int = 10) -> Optional[Dict]:
        """
        æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
        
        Args:
            file_path: è¦æœç´¢çš„æ–‡ä»¶è·¯å¾„
            top_k: è¿”å›æœ€ç›¸ä¼¼çš„å‰Kä¸ªç»“æœ
            
        Returns:
            æœç´¢ç»“æœå­—å…¸æˆ–None
        """
        try:
            # å‡†å¤‡è¯·æ±‚æ•°æ®
            request_data = {
                'file_path': os.path.abspath(file_path),
                'top_k': top_k
            }
            
            logger.info(f"ğŸ” æ­£åœ¨æœç´¢æ–‡ä»¶: {file_path}")
            logger.info(f"ğŸ“Š è¯·æ±‚TOP-{top_k}ç›¸ä¼¼æ ·æœ¬")
            
            start_time = time.time()
            
            # å‘é€APIè¯·æ±‚
            response = self.session.post(
                f"{self.base_url}/similarity/api/search",
                json=request_data,
                timeout=self.timeout
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            response.raise_for_status()
            result = response.json()
            
            if result.get('success'):
                result_count = len(result.get('results', []))
                logger.info(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {result_count} ä¸ªç›¸ä¼¼æ ·æœ¬ï¼Œè€—æ—¶ {duration:.2f} ç§’")
                
                # æ·»åŠ é¢å¤–çš„å…ƒæ•°æ®
                result['search_duration'] = duration
                result['search_timestamp'] = datetime.now().isoformat()
                result['search_file'] = file_path
                result['client_version'] = "1.0.0"
                
                return result
            else:
                logger.error(f"âŒ æœç´¢å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error(f"âŒ æœç´¢è¶…æ—¶: {file_path}")
            return None
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ æœç´¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return None

class FileScanner:
    """æ–‡ä»¶æ‰«æå™¨ç±»"""
    
    # æ”¯æŒçš„å¯æ‰§è¡Œæ–‡ä»¶æ‰©å±•å
    EXECUTABLE_EXTENSIONS = {
        '.exe', '.dll', '.sys', '.scr', '.com', '.bat', '.cmd',  # Windows
        '.elf', '.so', '.bin', '.out',  # Linux
        '.app', '.dylib', '.bundle',  # macOS
        '.apk', '.dex',  # Android
        '.jar', '.class',  # Java
        '.py', '.sh', '.pl', '.rb'  # Scripts
    }
    
    # æ”¯æŒçš„MIMEç±»å‹
    EXECUTABLE_MIMES = {
        'application/x-executable',
        'application/x-sharedlib',
        'application/x-object',
        'application/octet-stream',
        'application/x-dosexec',
        'application/x-mach-binary',
        'text/x-shellscript'
    }
    
    def __init__(self, use_magic: bool = True):
        """
        åˆå§‹åŒ–æ–‡ä»¶æ‰«æå™¨
        
        Args:
            use_magic: æ˜¯å¦ä½¿ç”¨libmagicè¿›è¡Œæ–‡ä»¶ç±»å‹æ£€æµ‹
        """
        self.use_magic = use_magic
        
    def is_executable_file(self, file_path: str) -> bool:
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºå¯æ‰§è¡Œæ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦ä¸ºå¯æ‰§è¡Œæ–‡ä»¶
        """
        if not os.path.isfile(file_path):
            return False
            
        try:
            # é¦–å…ˆæ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            file_ext = Path(file_path).suffix.lower()
            if file_ext in self.EXECUTABLE_EXTENSIONS:
                return True
                
            # å¦‚æœå¯ç”¨magicæ£€æµ‹
            if self.use_magic:
                try:
                    # æ£€æŸ¥MIMEç±»å‹
                    mime_type = magic.from_file(file_path, mime=True)
                    if mime_type in self.EXECUTABLE_MIMES:
                        return True
                        
                    # æ£€æŸ¥æ–‡ä»¶æè¿°
                    file_desc = magic.from_file(file_path)
                    if any(keyword in file_desc.lower() for keyword in 
                          ['executable', 'binary', 'elf', 'pe32', 'mach-o']):
                        return True
                        
                except Exception as e:
                    logger.debug(f"Magicæ£€æµ‹å¤±è´¥ {file_path}: {e}")
                    
            # æ£€æŸ¥æ–‡ä»¶æƒé™ï¼ˆLinux/macOSï¼‰
            if os.access(file_path, os.X_OK):
                return True
                
        except Exception as e:
            logger.debug(f"æ–‡ä»¶ç±»å‹æ£€æŸ¥å¤±è´¥ {file_path}: {e}")
            
        return False
        
    def scan_directory(self, directory: str, recursive: bool = True, 
                      max_files: Optional[int] = None) -> List[str]:
        """
        æ‰«æç›®å½•ä¸­çš„å¯æ‰§è¡Œæ–‡ä»¶
        
        Args:
            directory: ç›®æ ‡ç›®å½•è·¯å¾„
            recursive: æ˜¯å¦é€’å½’æ‰«æå­ç›®å½•
            max_files: æœ€å¤§æ–‡ä»¶æ•°é‡é™åˆ¶
            
        Returns:
            å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        logger.info(f"ğŸ“ å¼€å§‹æ‰«æç›®å½•: {directory}")
        logger.info(f"ğŸ”„ é€’å½’æ‰«æ: {'æ˜¯' if recursive else 'å¦'}")
        
        executable_files = []
        scanned_count = 0
        
        try:
            if recursive:
                # é€’å½’æ‰«æ
                for root, dirs, files in os.walk(directory):
                    for file in files:
                        file_path = os.path.join(root, file)
                        scanned_count += 1
                        
                        if scanned_count % 100 == 0:
                            logger.info(f"å·²æ‰«æ {scanned_count} ä¸ªæ–‡ä»¶...")
                            
                        if self.is_executable_file(file_path):
                            executable_files.append(file_path)
                            logger.debug(f"âœ… å‘ç°å¯æ‰§è¡Œæ–‡ä»¶: {file_path}")
                            
                            if max_files and len(executable_files) >= max_files:
                                logger.info(f"âš ï¸ å·²è¾¾åˆ°æœ€å¤§æ–‡ä»¶æ•°é‡é™åˆ¶: {max_files}")
                                break
                                
                    if max_files and len(executable_files) >= max_files:
                        break
            else:
                # ä»…æ‰«æå½“å‰ç›®å½•
                for file in os.listdir(directory):
                    file_path = os.path.join(directory, file)
                    scanned_count += 1
                    
                    if self.is_executable_file(file_path):
                        executable_files.append(file_path)
                        logger.debug(f"âœ… å‘ç°å¯æ‰§è¡Œæ–‡ä»¶: {file_path}")
                        
                        if max_files and len(executable_files) >= max_files:
                            logger.info(f"âš ï¸ å·²è¾¾åˆ°æœ€å¤§æ–‡ä»¶æ•°é‡é™åˆ¶: {max_files}")
                            break
                            
        except Exception as e:
            logger.error(f"âŒ æ‰«æç›®å½•æ—¶å‡ºé”™: {e}")
            
        logger.info(f"ğŸ“Š æ‰«æå®Œæˆ: å…±æ‰«æ {scanned_count} ä¸ªæ–‡ä»¶ï¼Œå‘ç° {len(executable_files)} ä¸ªå¯æ‰§è¡Œæ–‡ä»¶")
        return executable_files

class BatchProcessor:
    """æ‰¹é‡å¤„ç†å™¨ç±»"""
    
    def __init__(self, api_client: BinDiffAPIClient, max_workers: int = 4):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        
        Args:
            api_client: APIå®¢æˆ·ç«¯å®ä¾‹
            max_workers: æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
        """
        self.api_client = api_client
        self.max_workers = max_workers
        
    def process_files_batch(self, file_paths: List[str], top_k: int = 10,
                           progress_callback=None) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡å¤„ç†æ–‡ä»¶
        
        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            top_k: æ¯ä¸ªæ–‡ä»¶è¿”å›çš„ç›¸ä¼¼æ ·æœ¬æ•°é‡
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            å¤„ç†ç»“æœåˆ—è¡¨
        """
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶")
        logger.info(f"âš™ï¸ å¹¶å‘çº¿ç¨‹æ•°: {self.max_workers}")
        
        results = []
        completed = 0
        failed = 0
        
        start_time = time.time()
        
        # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(self._process_single_file, file_path, top_k): file_path
                for file_path in file_paths
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_file):
                file_path = future_to_file[future]
                completed += 1
                
                try:
                    result = future.result()
                    if result:
                        results.append({
                            'file_path': file_path,
                            'success': True,
                            'data': result
                        })
                        logger.info(f"âœ… [{completed}/{len(file_paths)}] å®Œæˆ: {os.path.basename(file_path)}")
                    else:
                        failed += 1
                        results.append({
                            'file_path': file_path,
                            'success': False,
                            'error': 'æœç´¢å¤±è´¥'
                        })
                        logger.error(f"âŒ [{completed}/{len(file_paths)}] å¤±è´¥: {os.path.basename(file_path)}")
                        
                except Exception as e:
                    failed += 1
                    results.append({
                        'file_path': file_path,
                        'success': False,
                        'error': str(e)
                    })
                    logger.error(f"âŒ [{completed}/{len(file_paths)}] å¼‚å¸¸: {os.path.basename(file_path)} - {e}")
                    
                # è°ƒç”¨è¿›åº¦å›è°ƒ
                if progress_callback:
                    progress_callback(completed, len(file_paths), failed)
                    
        end_time = time.time()
        duration = end_time - start_time
        
        success_count = len(file_paths) - failed
        logger.info(f"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ:")
        logger.info(f"   âœ… æˆåŠŸ: {success_count}/{len(file_paths)}")
        logger.info(f"   âŒ å¤±è´¥: {failed}/{len(file_paths)}")
        logger.info(f"   â±ï¸ æ€»è€—æ—¶: {duration:.2f} ç§’")
        logger.info(f"   ğŸ“ˆ å¹³å‡é€Ÿåº¦: {len(file_paths)/duration:.2f} æ–‡ä»¶/ç§’")
        
        return results
        
    def _process_single_file(self, file_path: str, top_k: int) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            return self.api_client.search_similarity(file_path, top_k)
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

class ResultManager:
    """ç»“æœç®¡ç†å™¨ç±»"""
    
    @staticmethod
    def save_results(results: List[Dict[str, Any]], output_file: str, 
                    include_metadata: bool = True) -> bool:
        """
        ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
        
        Args:
            results: ç»“æœåˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            include_metadata: æ˜¯å¦åŒ…å«å…ƒæ•°æ®
            
        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            # å‡†å¤‡è¾“å‡ºæ•°æ®
            output_data = {
                'results': results
            }
            
            if include_metadata:
                output_data['metadata'] = {
                    'total_files': len(results),
                    'successful_files': sum(1 for r in results if r.get('success')),
                    'failed_files': sum(1 for r in results if not r.get('success')),
                    'generation_time': datetime.now().isoformat(),
                    'client_version': '1.0.0'
                }
                
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(output_file)
            if output_dir:  # åªæœ‰å½“ç›®å½•ä¸ä¸ºç©ºæ—¶æ‰åˆ›å»º
                os.makedirs(output_dir, exist_ok=True)
            
            # ä¿å­˜åˆ°JSONæ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
                
            logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return False
            
    @staticmethod
    def filter_results(results: List[Dict[str, Any]], 
                      min_similarity: float = 0.0,
                      families: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """
        è¿‡æ»¤ç»“æœ
        
        Args:
            results: åŸå§‹ç»“æœ
            min_similarity: æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼
            families: æŒ‡å®šçš„å®¶æ—åˆ—è¡¨
            
        Returns:
            è¿‡æ»¤åçš„ç»“æœ
        """
        filtered_results = []
        
        for result in results:
            if not result.get('success'):
                filtered_results.append(result)
                continue
                
            data = result.get('data', {})
            search_results = data.get('results', [])
            
            # è¿‡æ»¤ç›¸ä¼¼åº¦å’Œå®¶æ—
            filtered_search_results = []
            for item in search_results:
                similarity = item.get('similarity', 0)
                family = item.get('family', '')
                
                if similarity >= min_similarity:
                    if not families or family in families:
                        filtered_search_results.append(item)
                        
            # æ›´æ–°ç»“æœ
            if filtered_search_results:
                new_data = data.copy()
                new_data['results'] = filtered_search_results
                new_data['total_results'] = len(filtered_search_results)
                
                filtered_results.append({
                    'file_path': result['file_path'],
                    'success': True,
                    'data': new_data
                })
            else:
                # å¦‚æœæ²¡æœ‰åŒ¹é…ç»“æœï¼Œæ ‡è®°ä¸ºå¤±è´¥
                filtered_results.append({
                    'file_path': result['file_path'],
                    'success': False,
                    'error': 'No results match filter criteria'
                })
                
        return filtered_results

def create_progress_callback():
    """åˆ›å»ºè¿›åº¦å›è°ƒå‡½æ•°"""
    def progress_callback(completed: int, total: int, failed: int):
        percentage = (completed / total) * 100
        success_rate = ((completed - failed) / completed) * 100 if completed > 0 else 0
        
        logger.info(f"ğŸ“ˆ è¿›åº¦: {completed}/{total} ({percentage:.1f}%) | "
                   f"æˆåŠŸç‡: {success_rate:.1f}% | å¤±è´¥: {failed}")
    
    return progress_callback

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='BinDiff APIå®¢æˆ·ç«¯ - æ‰¹é‡ç›¸ä¼¼åº¦æœç´¢å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æ‰«æç›®å½•å¹¶æœç´¢ç›¸ä¼¼æ ·æœ¬
  %(prog)s /path/to/malware/samples -o results.json
  
  # æŒ‡å®šæœåŠ¡åœ°å€å’ŒTOP-Kå‚æ•°
  %(prog)s /path/to/samples --url http://192.168.1.100:5001 --top-k 20
  
  # é€’å½’æ‰«æå¹¶é™åˆ¶æ–‡ä»¶æ•°é‡
  %(prog)s /path/to/samples -r --max-files 100
  
  # è¿‡æ»¤ç»“æœï¼ˆæœ€å°ç›¸ä¼¼åº¦å’ŒæŒ‡å®šå®¶æ—ï¼‰
  %(prog)s /path/to/samples --min-similarity 0.8 --families Patchwork APT29
  
  # è°ƒæ•´å¹¶å‘å‚æ•°
  %(prog)s /path/to/samples --workers 8 --timeout 600
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('target_directory',
                       help='ç›®æ ‡ç›®å½•è·¯å¾„')
    
    # è¾“å‡ºé€‰é¡¹
    parser.add_argument('-o', '--output', 
                       default=f'bindiff_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: bindiff_results_<timestamp>.json)')
    
    # æœåŠ¡é…ç½®
    parser.add_argument('--url', default='http://localhost:5001',
                       help='BinDiffæœåŠ¡URL (é»˜è®¤: http://localhost:5001)')
    parser.add_argument('--timeout', type=int, default=300,
                       help='è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 300)')
    
    # æœç´¢å‚æ•°
    parser.add_argument('--top-k', type=int, default=10,
                       help='è¿”å›æœ€ç›¸ä¼¼çš„å‰Kä¸ªç»“æœ (é»˜è®¤: 10)')
    
    # æ‰«æé€‰é¡¹
    parser.add_argument('-r', '--recursive', action='store_true',
                       help='é€’å½’æ‰«æå­ç›®å½•')
    parser.add_argument('--max-files', type=int,
                       help='æœ€å¤§æ–‡ä»¶æ•°é‡é™åˆ¶')
    parser.add_argument('--no-magic', action='store_true',
                       help='ç¦ç”¨libmagicæ–‡ä»¶ç±»å‹æ£€æµ‹')
    
    # å¹¶å‘é€‰é¡¹
    parser.add_argument('--workers', type=int, default=4,
                       help='å¹¶å‘å·¥ä½œçº¿ç¨‹æ•° (é»˜è®¤: 4)')
    
    # è¿‡æ»¤é€‰é¡¹
    parser.add_argument('--min-similarity', type=float, default=0.0,
                       help='æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼ (é»˜è®¤: 0.0)')
    parser.add_argument('--families', nargs='+',
                       help='æŒ‡å®šæ¶æ„è½¯ä»¶å®¶æ—åˆ—è¡¨')
    
    # å…¶ä»–é€‰é¡¹
    parser.add_argument('--check-only', action='store_true',
                       help='ä»…æ£€æŸ¥æœåŠ¡çŠ¶æ€ï¼Œä¸æ‰§è¡Œæœç´¢')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='å¯ç”¨è¯¦ç»†æ—¥å¿—è¾“å‡º')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
        
    # éªŒè¯å‚æ•°
    if not os.path.isdir(args.target_directory):
        logger.error(f"âŒ ç›®æ ‡ç›®å½•ä¸å­˜åœ¨: {args.target_directory}")
        return 1
        
    if args.top_k <= 0 or args.top_k > 100:
        logger.error(f"âŒ TOP-Kå€¼å¿…é¡»åœ¨1-100ä¹‹é—´: {args.top_k}")
        return 1
        
    logger.info(f"ğŸš€ BinDiff APIå®¢æˆ·ç«¯å¯åŠ¨")
    logger.info(f"ğŸ“ ç›®æ ‡ç›®å½•: {args.target_directory}")
    logger.info(f"ğŸŒ æœåŠ¡åœ°å€: {args.url}")
    logger.info(f"ğŸ“Š TOP-K: {args.top_k}")
    
    try:
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        api_client = BinDiffAPIClient(args.url, args.timeout)
        
        # æ£€æŸ¥æœåŠ¡çŠ¶æ€
        if not api_client.check_service_health():
            logger.error("âŒ BinDiffæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
            return 1
            
        if args.check_only:
            logger.info("âœ… æœåŠ¡çŠ¶æ€æ£€æŸ¥å®Œæˆ")
            return 0
            
        # åˆå§‹åŒ–æ–‡ä»¶æ‰«æå™¨
        scanner = FileScanner(use_magic=not args.no_magic)
        
        # æ‰«ææ–‡ä»¶
        executable_files = scanner.scan_directory(
            args.target_directory,
            recursive=args.recursive,
            max_files=args.max_files
        )
        
        if not executable_files:
            logger.warning("âš ï¸ æœªå‘ç°ä»»ä½•å¯æ‰§è¡Œæ–‡ä»¶")
            return 0
            
        # åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
        processor = BatchProcessor(api_client, args.workers)
        
        # æ‰§è¡Œæ‰¹é‡å¤„ç†
        progress_callback = create_progress_callback()
        results = processor.process_files_batch(
            executable_files,
            args.top_k,
            progress_callback
        )
        
        # è¿‡æ»¤ç»“æœ
        if args.min_similarity > 0 or args.families:
            logger.info(f"ğŸ” åº”ç”¨è¿‡æ»¤æ¡ä»¶...")
            results = ResultManager.filter_results(
                results,
                args.min_similarity,
                args.families
            )
            
        # ä¿å­˜ç»“æœ
        if ResultManager.save_results(results, args.output):
            logger.info(f"ğŸ‰ å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {args.output}")
            
            # æä¾›æ¸…ç†å»ºè®®
            api_client.request_cleanup()
            
            return 0
        else:
            logger.error("âŒ ä¿å­˜ç»“æœå¤±è´¥")
            return 1
            
    except KeyboardInterrupt:
        logger.info("âš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1

if __name__ == '__main__':
    sys.exit(main())
